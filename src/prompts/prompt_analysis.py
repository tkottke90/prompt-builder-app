# In this Video (https://www.youtube.com/watch?v=jC4v5AS4RIM) by Jeff Su, he highlights his 
# philosophy of the 6 attributes of a LLM prompt.  This particular prompt attempts to analyze
# a prompt to identify these attributes.
from langchain_core.prompts.chat import ChatPromptTemplate
from langchain.output_parsers import ResponseSchema
from src.utils import prompt_util

def template_prompt_quality():
  analysisOutputFormat = prompt_util.createFormatInstructions(
    schemas=[
      ResponseSchema(name="score", description="a grading between 0 and 10 of how well the llm responds to the humans request", type="float"),
      ResponseSchema(name="score_explanation", description="a description of why the response received that score"),
    ]
  )
  
  return ChatPromptTemplate.from_template(
    partial_variables={
      "format_instructions": analysisOutputFormat
    },
    template="""# Information
You are an expert in generative AI interactions.
Below is a message generated by a user to a Large Language Model and the Model's response.
Your task is to evaluate the Model's response use the steps outlined in the Program below.
{format_instructions}

# User Message
{input}

# AI Response
{response} 

# Program
1. generate a score between 0 and 10 of how well the Generated Response responded to the Prompt Template
2. explain why this score was given based on your analysis 
"""
  )

def template_prompt_component():
  analysisOutputFormat = prompt_util.createFormatInstructions(
    schemas=[
      ResponseSchema(name="task", description="The task is the focus of the inquiry made by the user. It answers the question: 'what do you want me to do?'"),
      ResponseSchema(name="context", description="Details provided by the user to improve the LLM's ability to respond to the user's inquiry.  The goal is to help narrow the LLM's focus to the topic at hand."),
      ResponseSchema(name="exemplars", description="These are suggestions from the user on how to provide a relevant answer.  Such as by providing a framework such as the STAR Framework for interviewing"),
      ResponseSchema(name="persona", description="This is the perspective the user would like the LLM to take. A great tip is that a good persona would enable the LLM to act like an expert human the user would otherwise inquire about the topic specifically."),
      ResponseSchema(name="format", description="What format should the physical response take.  Examples might be: a JSON Markdown Blob, a Markdown Table, a Bullet Point list, or an email"),
      ResponseSchema(name="tone", description="What sort of language should the LLM use to respond.  This is only really used when generating a natural language response."),
    ]
  )
  
  return ChatPromptTemplate.from_template(
    partial_variables={
      "format_instructions": analysisOutputFormat
    },
    template="""# Information
You are an expert in generative AI interactions.
Below is a message generated by a user to a Large Language Model and the Model's response.
Your task is to evaluate the users message using the program outlined below.
{format_instructions}

# User Message
{input}

# Program
1. Identify the _task_ in the user's message.  If you cannot identify a task return an empty response.
2. Identify all _context_ provided by the user.  If you cannot identify a task return an empty response.
3. Identify any _exemplars_.  If you cannot identify a task return an empty response.
4. Identify the _persona_ in the user's message.  If you cannot identify a task return an empty response.
5. Identify the expected _format_ of the response.  If you cannot identify a task return an empty response.
6. Identify the _tone_ if one exists.  If you cannot identify a task return an empty response.
"""
  )